#gcloud container node-pools create embeddings-pool --cluster $CLUSTER_NAME 
#--accelerator type=nvidia-tesla-t4,count=1,gpu-driver-version=latest   --machine-type n1-standard-4 --ephemeral-storage-local-ssd=count=1   --enable-autoscaling --enable-image-streaming   --num-nodes=1 --min-nodes=0 --max-nodes=3 --shielded-secure-boot   --shielded-integrity-monitoring --node-version=1.29 --node-locations us-east1-c --region us-east1 --spot

apiVersion: apps/v1
kind: Deployment
metadata:
  name: tei-uve-large
spec:
  selector:
    matchLabels:
      app: tei-uve-large
  template:
    metadata:
      labels:
        app: tei-uve-large
    spec:
      volumes:
       - name: data
         emptyDir: {}
       - name: dshm
         emptyDir:
              medium: Memory
      #nodeSelector:
      #  cloud.google.com/gke-accelerator: nvidia-testla-t4
      containers:
      - name: embeddings
        image: ghcr.io/huggingface/text-embeddings-inference:1.2
        #resources:
        #    limits:
        #      nvidia.com/gpu: 1
        env:
            - name: model-id
              value: WhereIsAI/UAE-Large-V1
            - name: shm-size
              value: 1g
        ports:
        - containerPort: 80
        volumeMounts:
            - mountPath: /dev/shm
              name: dshm
            - mountPath: /data
              name: data
---
apiVersion: v1
kind: Service
metadata:
  name: tei-embedding
spec:
  type: LoadBalancer
  selector:
    app: tei-uve-large
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 80